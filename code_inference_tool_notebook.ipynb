{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b1b5be",
   "metadata": {},
   "source": [
    "# ðŸ§  Code Requirement Inference Tool\n",
    "This notebook helps you extract features from a Python script and infer business requirements using a glossary, optionally auto-generating one with spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8056b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import tokenize\n",
    "import difflib\n",
    "import json\n",
    "import re\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_features_from_code(code: str):\n",
    "    features = {\n",
    "        \"functions\": [],\n",
    "        \"variables\": [],\n",
    "        \"strings\": [],\n",
    "        \"comments\": []\n",
    "    }\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "    except SyntaxError:\n",
    "        return features\n",
    "\n",
    "    try:\n",
    "        tokens = tokenize.generate_tokens(StringIO(code).readline)\n",
    "        for token_type, token_string, *_ in tokens:\n",
    "            if token_type == tokenize.COMMENT:\n",
    "                features[\"comments\"].append(token_string.strip())\n",
    "    except tokenize.TokenError:\n",
    "        pass\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            doc = ast.get_docstring(node)\n",
    "            features[\"functions\"].append({\n",
    "                \"name\": node.name,\n",
    "                \"doc\": doc.splitlines()[0] if doc else \"\"\n",
    "            })\n",
    "        elif isinstance(node, ast.Assign):\n",
    "            for target in node.targets:\n",
    "                if isinstance(target, ast.Name):\n",
    "                    features[\"variables\"].append(target.id)\n",
    "        elif isinstance(node, ast.Expr) and isinstance(node.value, ast.Constant) and isinstance(node.value.value, str):\n",
    "            features[\"strings\"].append(node.value.value)\n",
    "        elif isinstance(node, ast.Constant) and isinstance(node.value, str):\n",
    "            features[\"strings\"].append(node.value.value)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c825f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_description(term):\n",
    "    doc = nlp(term.replace(\"_\", \" \"))\n",
    "    nouns = [t.text for t in doc if t.pos_ == \"NOUN\" or t.pos_ == \"PROPN\"]\n",
    "    base = \"This represents\"\n",
    "    if nouns:\n",
    "        return f\"{base} a {nouns[0].lower()}.\"\n",
    "    elif term.isidentifier():\n",
    "        return f\"{base} `{term}` in the system.\"\n",
    "    return f\"{base} an unknown concept: `{term}`.\"\n",
    "\n",
    "def scaffold_glossary(features):\n",
    "    terms = set(features.get(\"variables\", []) + features.get(\"strings\", []))\n",
    "    return {term: guess_description(term) for term in terms if isinstance(term, str)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_match(term, glossary):\n",
    "    matches = difflib.get_close_matches(term.lower(), glossary.keys(), n=1, cutoff=0.6)\n",
    "    if matches:\n",
    "        return matches[0], glossary[matches[0]]\n",
    "    return None, None\n",
    "\n",
    "def infer_requirements(features, glossary):\n",
    "    requirements = []\n",
    "    def score_confidence(evidence_count):\n",
    "        return round(min(1.0, 0.5 + 0.1 * evidence_count), 2)\n",
    "\n",
    "    for func in features[\"functions\"]:\n",
    "        if re.search(r\"fee|penalt\", func[\"name\"], re.IGNORECASE):\n",
    "            requirements.append({\n",
    "                \"text\": \"The system calculates a penalty or fee for a condition.\",\n",
    "                \"confidence\": score_confidence(2),\n",
    "                \"evidence\": f\"Function: `{func['name']}`\"\n",
    "            })\n",
    "\n",
    "    for var in features[\"variables\"]:\n",
    "        match, desc = fuzzy_match(var, glossary)\n",
    "        if match:\n",
    "            requirements.append({\n",
    "                \"text\": f\"The system uses `{match}`: {desc}.\",\n",
    "                \"confidence\": score_confidence(2),\n",
    "                \"evidence\": f\"Variable: `{var}` matched glossary: `{match}`\"\n",
    "            })\n",
    "\n",
    "    for comment in features[\"comments\"]:\n",
    "        if 'validate' in comment.lower():\n",
    "            requirements.append({\n",
    "                \"text\": \"The system includes validation logic.\",\n",
    "                \"confidence\": score_confidence(1),\n",
    "                \"evidence\": f\"Comment: `{comment}`\"\n",
    "            })\n",
    "\n",
    "    return requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¥ Input Python script (you can paste it here or load from file)\n",
    "code = \"\"\"# Calculate late fees\n",
    "def calculate_late_fee(days_overdue):\n",
    "    if days_overdue > 0:\n",
    "        return days_overdue * 5\n",
    "    return 0\n",
    "\n",
    "customer_id = \"ABC123\"\n",
    "\"\"\"\n",
    "\n",
    "features = extract_features_from_code(code)\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“š Generate glossary from code\n",
    "glossary = scaffold_glossary(features)\n",
    "glossary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ’¡ Infer requirements\n",
    "requirements = infer_requirements(features, glossary)\n",
    "requirements\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
